{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor \n",
    "- 숫자를 위한 컨테이너, 임의의 차원을 가지는 행렬의 일반화된 모습\n",
    "    1. scalar(0D tensor)\n",
    "    1. vector(1D tensor)\n",
    "    1. matrix(2D tensor)\n",
    "    1. 고차원Tensor\n",
    "- Tensor의 핵심 속성\n",
    "    1. rank\n",
    "    1. shape\n",
    "    1. dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# rank 축의 수를 확인\n",
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# 배열의 크기를 확인\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dtype('uint8')"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 속성을 확인\n",
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 넘파이로 텐서 조작하기\n",
    "배열에 있는 특정 원소들을  선택하는 것을 Slicing이라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(90, 28, 28)\n"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(90, 28, 28)\n"
    }
   ],
   "source": [
    "my_slice = train_images[10:100,:,:]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(90, 28, 28)\n"
    }
   ],
   "source": [
    "my_slice = train_images[10:100,0:28,0:28]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 데이터\n",
    "딥러닝 모델은 한 번에 전체 데이터셋을 처리하지 않는다. 그 대신 데이터를 작은 batch로 나눈다.\n",
    "\n",
    "> 예를 들어 데이터 크기가 128인 batch하나는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = train_images[:128]\n",
    "batch_2 = train_images[128:256]\n",
    "batch_n = train_images[128*n:256*(n+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 첫번째 축을 batch axis 또는 batch dimension이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터 데이터\n",
    "하나의 데이터 포인트가 벡터로 인코딩될 수 있다. 여기서 첫번째 축은 simple axis이고 두번재 축은 feature axis이다.\n",
    "> ex) 사람의 나이 우편번호 소득으로 구성된 인구 데이터 (10000,3)으로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시계열 데이터 또는 스퀀스 데이터\n",
    "> ex) 주식가격 데이터셋에서 하루거래는 (250, 390,3) 250일 390분 3개의데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 데이터\n",
    "> ex) (128,256,256,3) 128개수 256,256 컬러 3 데이터수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비디오 데이터\n",
    "> ex) (samples, frames, height, width, color_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.layer.Dense(512,activation='rulu')\n",
    "# output = rulu(dot(W,input)+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## broadcasting\n",
    "- 모호하지 않고 실행 가능하다면 작은 텐서가 큰 텐서의 크기에 맞추어 broadcasting된다.\n",
    "    1. 큰 텐서의 ndim에 맞도록 작은 텐서에 축이 추가된다.\n",
    "    2. 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(64, 3, 32, 10)\n(64, 3, 32, 10)\n[[[[0.53902524 0.68069568 0.83475321 ... 0.99092984 0.62840726\n    0.92712243]\n   [0.570279   0.64209949 0.41452966 ... 0.51023284 0.85614206\n    0.79477092]\n   [0.84428562 0.23836484 0.89721236 ... 0.80524311 0.81101612\n    0.73110909]\n   ...\n   [0.64881993 0.48866088 0.67801712 ... 0.92861595 0.36632004\n    0.7246445 ]\n   [0.41661201 0.44478948 0.98299041 ... 0.67855984 0.93755897\n    0.84817024]\n   [0.52852919 0.77412166 0.10617864 ... 0.67281278 0.22685111\n    0.41401951]]\n\n  [[0.53902524 0.84580399 0.38672797 ... 0.90001551 0.63907384\n    0.61417383]\n   [0.71556852 0.61701234 0.80037077 ... 0.26258262 0.78252209\n    0.7771017 ]\n   [0.53333688 0.23836484 0.67167884 ... 0.71793842 0.71944801\n    0.60484609]\n   ...\n   [0.80723694 0.48866088 0.65369492 ... 0.92861595 0.462508\n    0.88580542]\n   [0.29059437 0.34855647 0.98299041 ... 0.67855984 0.40952786\n    0.97169501]\n   [0.89232142 0.9330987  0.16594639 ... 0.83104117 0.3372281\n    0.41401951]]\n\n  [[0.53902524 0.7932857  0.69703174 ... 0.71568287 0.62840726\n    0.61417383]\n   [0.570279   0.70950401 0.70183163 ... 0.89528197 0.69169666\n    0.69165961]\n   [0.53333688 0.47650621 0.67167884 ... 0.71793842 0.71944801\n    0.60484609]\n   ...\n   [0.50697578 0.50397521 0.86404707 ... 0.92861595 0.46438402\n    0.7246445 ]\n   [0.46201334 0.34042051 0.98299041 ... 0.67855984 0.40952786\n    0.27392485]\n   [0.52852919 0.68425912 0.59903228 ... 0.97775698 0.57063265\n    0.68988938]]]\n\n\n [[[0.54205482 0.90582834 0.74599711 ... 0.48361699 0.8944029\n    0.61417383]\n   [0.570279   0.97712391 0.36426421 ... 0.43084663 0.98387355\n    0.21833342]\n   [0.53333688 0.82087807 0.67167884 ... 0.93504464 0.71944801\n    0.60484609]\n   ...\n   [0.06159883 0.48866088 0.1360057  ... 0.92861595 0.72913962\n    0.7246445 ]\n   [0.56313983 0.34042051 0.98299041 ... 0.67855984 0.43844148\n    0.79040944]\n   [0.52852919 0.68425912 0.11733237 ... 0.67281278 0.09281574\n    0.51311762]]\n\n  [[0.6199818  0.27546967 0.38672797 ... 0.48361699 0.64914388\n    0.64896289]\n   [0.570279   0.06702919 0.36426421 ... 0.63069693 0.89624423\n    0.78784576]\n   [0.53333688 0.23836484 0.67167884 ... 0.71793842 0.71944801\n    0.60484609]\n   ...\n   [0.06159883 0.48866088 0.62389217 ... 0.92861595 0.73355769\n    0.7246445 ]\n   [0.82603511 0.39365295 0.98299041 ... 0.67855984 0.90340386\n    0.53502303]\n   [0.52852919 0.81920374 0.3046063  ... 0.67281278 0.74345036\n    0.51240784]]\n\n  [[0.53902524 0.08273233 0.38672797 ... 0.48361699 0.9638717\n    0.61417383]\n   [0.93339579 0.99921152 0.63709039 ... 0.73487099 0.69169666\n    0.33408331]\n   [0.53333688 0.86126727 0.7193778  ... 0.82450175 0.8675178\n    0.60484609]\n   ...\n   [0.63305358 0.84079791 0.0608319  ... 0.92861595 0.35466175\n    0.7246445 ]\n   [0.25377789 0.34042051 0.98299041 ... 0.96779138 0.63714272\n    0.27392485]\n   [0.68911665 0.68425912 0.23257505 ... 0.67281278 0.27234262\n    0.41401951]]]\n\n\n [[[0.53902524 0.34724134 0.71307045 ... 0.94060435 0.62840726\n    0.98016695]\n   [0.570279   0.82304528 0.43399843 ... 0.80869399 0.69169666\n    0.65113967]\n   [0.92360218 0.23836484 0.67167884 ... 0.71793842 0.92894301\n    0.60484609]\n   ...\n   [0.32181356 0.96312771 0.7360413  ... 0.92861595 0.69551204\n    0.7246445 ]\n   [0.78627133 0.34042051 0.98299041 ... 0.84475322 0.45528816\n    0.87736841]\n   [0.52852919 0.68425912 0.37149644 ... 0.94332938 0.35315659\n    0.41401951]]\n\n  [[0.93073998 0.61392415 0.38672797 ... 0.48361699 0.62840726\n    0.61417383]\n   [0.83651173 0.47831951 0.36426421 ... 0.60695712 0.69169666\n    0.88984812]\n   [0.53333688 0.69279321 0.67167884 ... 0.71793842 0.71944801\n    0.60484609]\n   ...\n   [0.06159883 0.48866088 0.09178603 ... 0.92861595 0.7997284\n    0.75140758]\n   [0.4088258  0.34042051 0.98299041 ... 0.67855984 0.40952786\n    0.27392485]\n   [0.8354909  0.70560676 0.99660575 ... 0.67281278 0.11224318\n    0.41401951]]\n\n  [[0.89827777 0.05171217 0.43675628 ... 0.48361699 0.62840726\n    0.61417383]\n   [0.92859555 0.45162227 0.69860025 ... 0.27701688 0.8182112\n    0.29544513]\n   [0.54738104 0.86499801 0.67167884 ... 0.71793842 0.74729028\n    0.75331523]\n   ...\n   [0.76177879 0.48866088 0.30864113 ... 0.92861595 0.84513665\n    0.83649684]\n   [0.81134077 0.34042051 0.98299041 ... 0.67855984 0.74982881\n    0.49601431]\n   [0.52852919 0.68425912 0.33299975 ... 0.67281278 0.60671526\n    0.88625168]]]\n\n\n ...\n\n\n [[[0.53902524 0.05171217 0.85963555 ... 0.48361699 0.62840726\n    0.61417383]\n   [0.73177058 0.34113328 0.36426421 ... 0.69565772 0.96294687\n    0.58394505]\n   [0.91354478 0.94838609 0.67167884 ... 0.71793842 0.94905278\n    0.60484609]\n   ...\n   [0.83518833 0.48866088 0.0608319  ... 0.99366046 0.41321234\n    0.7246445 ]\n   [0.41586894 0.34042051 0.98299041 ... 0.6919719  0.40952786\n    0.37665949]\n   [0.52852919 0.68425912 0.17276492 ... 0.67281278 0.12607698\n    0.41401951]]\n\n  [[0.53902524 0.32459675 0.89467464 ... 0.8254362  0.62840726\n    0.6499172 ]\n   [0.570279   0.85654503 0.70867507 ... 0.9358683  0.69169666\n    0.21833342]\n   [0.53333688 0.87087307 0.67167884 ... 0.71793842 0.97233799\n    0.90635769]\n   ...\n   [0.70107516 0.48866088 0.63137334 ... 0.92861595 0.20889726\n    0.7246445 ]\n   [0.64666808 0.74100507 0.98299041 ... 0.67855984 0.40952786\n    0.4075754 ]\n   [0.52852919 0.68425912 0.7492759  ... 0.76889931 0.38288339\n    0.48236147]]\n\n  [[0.53902524 0.05171217 0.88360774 ... 0.97792045 0.62840726\n    0.61417383]\n   [0.570279   0.73785447 0.5652161  ... 0.26258262 0.69169666\n    0.21833342]\n   [0.53333688 0.94260512 0.90951868 ... 0.71793842 0.81763646\n    0.60484609]\n   ...\n   [0.27646378 0.6355287  0.64946332 ... 0.92861595 0.74113738\n    0.7246445 ]\n   [0.72717334 0.35627926 0.98299041 ... 0.67855984 0.40952786\n    0.91353787]\n   [0.52852919 0.68425912 0.10652702 ... 0.76544512 0.4298334\n    0.51919335]]]\n\n\n [[[0.53902524 0.46715234 0.60397581 ... 0.92060964 0.62840726\n    0.8583659 ]\n   [0.64098965 0.57705755 0.40801266 ... 0.26258262 0.69169666\n    0.66291573]\n   [0.53333688 0.59273488 0.67167884 ... 0.96130392 0.71944801\n    0.96639788]\n   ...\n   [0.98783229 0.48866088 0.0608319  ... 0.92861595 0.40878565\n    0.7246445 ]\n   [0.30019631 0.34042051 0.98299041 ... 0.67855984 0.78504996\n    0.28301013]\n   [0.52852919 0.68425912 0.82907037 ... 0.67281278 0.70503377\n    0.41401951]]\n\n  [[0.53902524 0.67724355 0.48516891 ... 0.66137784 0.86100848\n    0.61417383]\n   [0.96259577 0.71288559 0.36426421 ... 0.34930618 0.69169666\n    0.21833342]\n   [0.53333688 0.90565477 0.74870918 ... 0.71793842 0.88121731\n    0.60484609]\n   ...\n   [0.30272486 0.48866088 0.76027049 ... 0.92861595 0.4400234\n    0.78763527]\n   [0.88501465 0.92850586 0.98299041 ... 0.67855984 0.69931319\n    0.27392485]\n   [0.52852919 0.68425912 0.68710448 ... 0.77903614 0.11935831\n    0.81147665]]\n\n  [[0.82141489 0.8576907  0.38672797 ... 0.84720663 0.69153625\n    0.84426987]\n   [0.80518612 0.60114753 0.67236561 ... 0.91296822 0.69169666\n    0.7897878 ]\n   [0.72893377 0.23836484 0.67167884 ... 0.71793842 0.87289791\n    0.65228135]\n   ...\n   [0.22350259 0.48866088 0.63826953 ... 0.92861595 0.92997428\n    0.7246445 ]\n   [0.98544621 0.34042051 0.98299041 ... 0.67855984 0.72353022\n    0.27392485]\n   [0.97509646 0.68425912 0.41996072 ... 0.67281278 0.46802213\n    0.41401951]]]\n\n\n [[[0.53902524 0.7008593  0.38672797 ... 0.48361699 0.62840726\n    0.61417383]\n   [0.93981872 0.56097475 0.36426421 ... 0.26258262 0.69169666\n    0.78428015]\n   [0.53333688 0.23836484 0.67167884 ... 0.90743343 0.71944801\n    0.60484609]\n   ...\n   [0.20552246 0.76641912 0.19351695 ... 0.92861595 0.19912449\n    0.7246445 ]\n   [0.95521975 0.34042051 0.98299041 ... 0.67855984 0.40952786\n    0.88472594]\n   [0.82209477 0.74264226 0.97424746 ... 0.890846   0.99733374\n    0.74545057]]\n\n  [[0.53902524 0.05171217 0.67087261 ... 0.62240368 0.66500667\n    0.61417383]\n   [0.93097611 0.88357259 0.36426421 ... 0.39870778 0.69169666\n    0.21833342]\n   [0.53333688 0.23836484 0.67167884 ... 0.71793842 0.71944801\n    0.78759436]\n   ...\n   [0.34594683 0.69821547 0.34754597 ... 0.92861595 0.08545231\n    0.7246445 ]\n   [0.94510304 0.6676867  0.98299041 ... 0.67855984 0.40952786\n    0.27392485]\n   [0.52852919 0.68425912 0.3328375  ... 0.67281278 0.38610678\n    0.51072425]]\n\n  [[0.6492113  0.8190876  0.52234201 ... 0.48361699 0.62840726\n    0.61417383]\n   [0.570279   0.84853152 0.36426421 ... 0.26258262 0.73717708\n    0.3221121 ]\n   [0.53333688 0.23836484 0.67167884 ... 0.71793842 0.71944801\n    0.60484609]\n   ...\n   [0.23460373 0.95316779 0.45834392 ... 0.92861595 0.67750442\n    0.7246445 ]\n   [0.73912083 0.92292005 0.98299041 ... 0.67855984 0.90701244\n    0.31868873]\n   [0.71382617 0.96456282 0.37242106 ... 0.7148253  0.65925751\n    0.82653616]]]]\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64,3,32,10))\n",
    "y = np.random.random((32,10))\n",
    "\n",
    "z = np.maximum(x,y)\n",
    "print(x.shape)\n",
    "print(z.shape)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  dot operation(tensor product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 크기 변환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 연산의 기하학적 해석\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망의 엔진 : 그래디언트 기반 최적화\n",
    "        output=relu(dot(W,input)+b)\n",
    "\n",
    "        W,b : weight, trainable parameter\n",
    "        W : kernel\n",
    "        b : bias\n",
    "1. 처음 weight은 random initialization 상태이다.\n",
    "1. 훈련을 통해 점진적 조정이 일어난다.\n",
    "1. 이때 미분을 통하여 쉽게 목표값을 찾을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda79b86f2437604d89b80f2dd03c58d1de",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}